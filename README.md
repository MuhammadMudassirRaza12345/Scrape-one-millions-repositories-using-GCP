# Scrape-one-millions-repositories-using-GCP



Objective 1:
Get a list of the last 1 Million repos from Github, load data into a dataset, and run
an exploratory data analysis

source: [List public repositories.](https://docs.github.com/en/rest/repos/repos?apiVersion=2022-11-28#list-public-repositories)

Highlight any differences and trends in the dataset by user attributes, programming
languages, and other attributes.

Note: you need to fetch at least 600,000 repos for us to consider this adequately
completed.
Deliverable:

1) Share the codebase, the dataset, and any assets created, along with
instructions to run it.

3) Would be assessed on:
   
a) Quality, testing, and reliability of the data pipeline

b) Visualization of results

Focus on identifying and analyzing distinct audiences in the
dataset (you can use descriptive or predictive approaches).

# Solution: [instruction.pdf](https://github.com/MuhammadMudassirRaza12345/Scrape-one-millions-repositories-using-GCP/blob/main/instruction.pdf)

<img src="https://github.com/MuhammadMudassirRaza12345/Scrape-one-millions-repositories-using-GCP/blob/main/Github-public%20repos.png">
<!-- https://github.com/MuhammadMudassirRaza12345/Scrape-one-millions-repositories-using-GCP/blob/main/Github-public%20repos.png -->
