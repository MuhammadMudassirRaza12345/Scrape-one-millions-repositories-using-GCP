# Scrape-one-millions-repositories-using-GCP

Objective 1:
Get a list of the last 1 Million repos from Github, load data into a dataset, and run
an exploratory data analysis

source: [List public repositories.](https://docs.github.com/en/rest/repos/repos?apiVersion=2022-11-28#list-public-repositories)

Highlight any differences and trends in the dataset by user attributes, programming
languages, and other attributes.

Note: you need to fetch at least 600,000 repos for us to consider this adequately
completed.
Deliverable:

1) Share the codebase, the dataset, and any assets created, along with
instructions to run it.

3) Would be assessed on:
a) Quality, testing, and reliability of the data pipeline
-
Bonus: Loading data into a cloud data warehouse (GCP, Azure,
AWS, etc.)
b) Visualization of results
-
Focus on identifying and analyzing distinct audiences in the
dataset (you can use descriptive or predictive approaches).

# Solution: instruction.pdf
